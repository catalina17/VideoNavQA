# VideoNavQA
Resources for *VideoNavQA: Bridging the Gap between Visual and Embodied Question Answering* (to appear at BMVC 2019) [[arXiv](https://arxiv.org/abs/1908.04950)].

The VideoNavQA dataset can be found [here](https://drive.google.com/drive/folders/1DpEdjmVDMeJZ0ohS_TTp0HAjEbX0fU_m?usp=sharing).

Dependencies
* model evaluation:
  * [Faster-RCNN](https://github.com/catalina17/faster-rcnn.pytorch) fork (with VGG-16 pre-trained [weights](https://www.dropbox.com/s/s3brpk0bdq60nyb/vgg16_caffe.pth?dl=0))
* data generation:
  * [EmbodiedQA](https://github.com/catalina17/EmbodiedQA) fork
  * [House3D](https://github.com/catalina17/House3D) fork
  * SUNCG [dataset](https://sscnet.cs.princeton.edu)
  * SUNCG [toolbox](https://github.com/jjhartmann/SUNCGtoolbox)

Full README coming soon!
